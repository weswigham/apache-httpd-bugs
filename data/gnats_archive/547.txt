From nobody@hyperreal.com  Mon May  5 07:02:27 1997
Received: (from nobody@localhost)
	by hyperreal.com (8.8.5/8.8.5) id HAA13322;
	Mon, 5 May 1997 07:02:27 -0700 (PDT)
Message-Id: <199705051402.HAA13322@hyperreal.com>
Date: Mon, 5 May 1997 07:02:27 -0700 (PDT)
From: Jesper Holck <holck@knold.ballehs.dk>
Reply-To: holck@knold.ballehs.dk
To: apbugs@hyperreal.com
Subject: 830 "lingering close lost connection to client" in 4 minutes
X-Send-Pr-Version: 3.2

>Number:         547
>Category:       os-ultrix
>Synopsis:       830 "lingering close lost connection to client" in 4 minutes
>Confidential:   no
>Severity:       non-critical
>Priority:       medium
>Responsible:    apache
>State:          closed
>Class:          sw-bug
>Submitter-Id:   apache
>Arrival-Date:   Mon May  5 07:10:00 1997
>Last-Modified:  Sun Jun 29 19:00:05 PDT 1997
>Originator:     holck@knold.ballehs.dk
>Organization:
>Release:        1.2b10
>Environment:
uname -a says:
ULTRIX BALMAX.ballehs.dk 4.5 0 RISC

Apache compiled with gcc with only a few warnings.
>Description:
This morning my error_log was filled with 830 messages
"lingering close lost connection to client ......." in only 4 minutes!

In between were some of these messages:
"access to /usr/local/etc/apache/cgi-bin/Count.cgi 
failed for 194.182.98.21, reason: couldn't spawn child process"

Count.cgi seems to work OK as of this writing (afternoon, same day).

I have not had this problem with earlier versions. The only change
in configuration between this version and the last (b8) has been
the inclusion of the server-info module and handler.

Jesper Holck

>How-To-Repeat:
Don't know.
>Fix:
No
>Audit-Trail:
State-Changed-From-To: open-analyzed
State-Changed-By: dgaudet
State-Changed-When: Mon May  5 12:11:58 PDT 1997
State-Changed-Why:
This looks like your network had high packet loss for a short
period of time causing all of apache's children to be tied up.
That it couldn't spawn a new child indicates you have MaxClients
set too high for your system.  That is, you've got a small process
table, or a limit of the number of processes a single uid can
run.

Is there any way to verify that during the same period you had
network problems?

Thanks
Dean
State-Changed-From-To: analyzed-closed
State-Changed-By: dgaudet
State-Changed-When: Sun Jun 29 19:00:04 PDT 1997
State-Changed-Why:
No response, assuming a fluke network event caused the errors.

Dean
>Unformatted:


